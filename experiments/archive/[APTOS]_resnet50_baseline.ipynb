{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "[APTOS] resnet50 baseline.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMWJKHK2JiLK",
        "colab_type": "code",
        "outputId": "bace86f6-e28f-4b1c-f66e-d01291bb7cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "kaggle = False\n",
        "import os\n",
        "if not kaggle:\n",
        "  # You need to run download_data.ipynb first if not already done: https://colab.research.google.com/drive/1n_gPC9tSENd_qvsc3BsoAS93mwe7jdj5?authuser=1#scrollTo=FI59CeAJGaI_\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  os.chdir('drive/My Drive/Colab Notebooks/APTOS/dat')\n",
        "  root = './'\n",
        "else:\n",
        "  root = '/kaggle/input/aptos2019-blindness-detection/'  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ_t3QoLJZbW",
        "colab_type": "text"
      },
      "source": [
        "* Update: changing the batch_size from 32 to 128 when warm up the model, adding Kappa loss from this kernel: https://www.kaggle.com/christofhenkel/weighted-kappa-loss-for-keras-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "FIIzSTK_JZbd",
        "colab_type": "code",
        "outputId": "34b74ea2-69b9-4502-a666-26ff841db275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import skimage.io\n",
        "from skimage.transform import resize\n",
        "from imgaug import augmenters as iaa\n",
        "from tqdm import tqdm\n",
        "import PIL\n",
        "from PIL import Image, ImageOps\n",
        "import cv2\n",
        "from sklearn.utils import class_weight, shuffle\n",
        "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score, accuracy_score\n",
        "from keras.utils import Sequence\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "WORKERS = 2\n",
        "CHANNEL = 3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "SIZE = 300\n",
        "NUM_CLASSES = 5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Sksm7KtJJZbi",
        "colab_type": "code",
        "outputId": "3f18a198-42b8-4ae9-de74-e5980bdc62c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "df_train = pd.read_csv(root + '/train.csv')\n",
        "df_test = pd.read_csv(root + '/test.csv')\n",
        "\n",
        "x = df_train['id_code']\n",
        "y = df_train['diagnosis']\n",
        "\n",
        "x, y = shuffle(x, y, random_state=8)\n",
        "y.hist()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4e445f00f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVd0lEQVR4nO3df4xlZ33f8fcnNhDkITaJ6dTxmq6R\nFiT/SFx2ZFylQTOFwGIQhhbRtVyw+ZGFAmpQkIKdpoVCLVkthgo7MV2wZbs4Hiwc2I1jlzqOVw5S\nDXipw9qAYQ2L6pW127BmNwMrt2u+/WPOhst6ftwfM3cWP++XdHXPfZ7nnPM9Z+/9zLnnnns3VYUk\nqQ2/tNYFSJLGx9CXpIYY+pLUEENfkhpi6EtSQ05c6wKWc+qpp9b69euHmvfHP/4xJ5100soWtAKs\nazDWNRjrGswzsa6dO3f+bVW9YMHOqjqubxs3bqxh3XvvvUPPu5qsazDWNRjrGswzsS7ggVokUz29\nI0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTnuf4ZhFLv2HuSyy/9i7Ovd\nc9Vrx75OSeqHR/qS1BBDX5IasmzoJ7khyf4kD/W0fS7Jg91tT5IHu/b1SQ739H2qZ56NSXYl2Z3k\nk0myOpskSVpMP+f0bwSuBW4+2lBV//LodJKrgYM94x+tqvMWWM51wO8CXwHuBDYBdw1esiRpWMse\n6VfVfcCBhfq6o/U3A7cutYwkpwG/UlX3dz/7eTPwhsHLlSSNIvMZvMygZD1wR1Wdc0z7y4GPV9VU\nz7iHge8Ah4A/qqq/TjIFXFVVr+zG/Tbwwap63SLr2wJsAZicnNw4Ozs7zLax/8BB9h0eataRnHv6\nyUv2z83NMTExMaZq+mddg7GuwVjXYEapa2ZmZufRXD7WqJdsXszPH+U/Drywqn6YZCPwxSRnD7rQ\nqtoKbAWYmpqq6enpoYq75pZtXL1r/Fel7rlkesn+HTt2MOw2rSbrGox1Dca6BrNadQ2diElOBP45\nsPFoW1U9CTzZTe9M8ijwYmAvsK5n9nVdmyRpjEa5ZPOVwLer6rGjDUlekOSEbvpFwAbge1X1OHAo\nyQXd5wBvBbaNsG5J0hD6uWTzVuB/Ai9J8liSd3Rdm3n6B7gvB77RXcL5eeDdVXX0Q+D3AJ8BdgOP\n4pU7kjR2y57eqaqLF2m/bIG224HbFxn/AHDOQn2SpPHwG7mS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x\n9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENf\nkhpi6EtSQwx9SWrIsqGf5IYk+5M81NP24SR7kzzY3S7s6bsiye4kjyR5dU/7pq5td5LLV35TJEnL\n6edI/0Zg0wLtn6iq87rbnQBJzgI2A2d38/xJkhOSnAD8MfAa4Czg4m6sJGmMTlxuQFXdl2R9n8u7\nCJitqieB7yfZDZzf9e2uqu8BJJntxn5z4IolSUNLVS0/aD7076iqc7rHHwYuAw4BDwAfqKonklwL\n3F9Vn+3GXQ/c1S1mU1W9s2t/C/CyqnrfIuvbAmwBmJyc3Dg7OzvUxu0/cJB9h4eadSTnnn7ykv1z\nc3NMTEyMqZr+WddgrGsw1jWYUeqamZnZWVVTC/Ute6S/iOuAjwLV3V8NvH3IZT1NVW0FtgJMTU3V\n9PT0UMu55pZtXL1r2E0c3p5Lppfs37FjB8Nu02qyrsFY12CsazCrVddQiVhV+45OJ/k0cEf3cC9w\nRs/QdV0bS7RLksZkqEs2k5zW8/CNwNEre7YDm5M8J8mZwAbgq8DXgA1JzkzybOY/7N0+fNmSpGEs\ne6Sf5FZgGjg1yWPAh4DpJOcxf3pnD/AugKp6OMltzH9AewR4b1U91S3nfcCXgBOAG6rq4RXfGknS\nkvq5eufiBZqvX2L8lcCVC7TfCdw5UHWSpBXlN3IlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9\nSWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jek\nhiwb+kluSLI/yUM9bf85ybeTfCPJF5Kc0rWvT3I4yYPd7VM982xMsivJ7iSfTJLV2SRJ0mL6OdK/\nEdh0TNvdwDlV9RvAd4Arevoerarzutu7e9qvA34X2NDdjl2mJGmVLRv6VXUfcOCYtv9RVUe6h/cD\n65ZaRpLTgF+pqvurqoCbgTcMV7IkaViZz+BlBiXrgTuq6pwF+v4c+FxVfbYb9zDzR/+HgD+qqr9O\nMgVcVVWv7Ob5beCDVfW6Rda3BdgCMDk5uXF2dnbwLQP2HzjIvsNDzTqSc08/ecn+ubk5JiYmxlRN\n/6xrMNY1GOsazCh1zczM7KyqqYX6ThylqCT/FjgC3NI1PQ68sKp+mGQj8MUkZw+63KraCmwFmJqa\nqunp6aHqu+aWbVy9a6RNHMqeS6aX7N+xYwfDbtNqsq7BWNdgrGswq1XX0ImY5DLgdcArulM2VNWT\nwJPd9M4kjwIvBvby86eA1nVtkqQxGuqSzSSbgD8AXl9VP+lpf0GSE7rpFzH/ge33qupx4FCSC7qr\ndt4KbBu5eknSQJY90k9yKzANnJrkMeBDzF+t8xzg7u7Ky/u7K3VeDnwkyf8Dfgq8u6qOfgj8Huav\nBHoucFd3kySN0bKhX1UXL9B8/SJjbwduX6TvAeBpHwRLksbHb+RKUkMMfUlqiKEvSQ0x9CWpIYa+\nJDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtS\nQwx9SWqIoS9JDTH0JakhfYV+khuS7E/yUE/brya5O8l3u/vnd+1J8skku5N8I8lLe+a5tBv/3SSX\nrvzmSJKW0u+R/o3ApmPaLgfuqaoNwD3dY4DXABu62xbgOpj/IwF8CHgZcD7woaN/KCRJ49FX6FfV\nfcCBY5ovAm7qpm8C3tDTfnPNux84JclpwKuBu6vqQFU9AdzN0/+QSJJWUaqqv4HJeuCOqjqne/yj\nqjqlmw7wRFWdkuQO4Kqq+nLXdw/wQWAa+OWq+o9d+78DDlfVxxZY1xbm3yUwOTm5cXZ2dqiN23/g\nIPsODzXrSM49/eQl++fm5piYmBhTNf2zrsH4/BqMdQ1mlLpmZmZ2VtXUQn0njlRVp6oqSX9/Pfpb\n3lZgK8DU1FRNT08PtZxrbtnG1btWZBMHsueS6SX7d+zYwbDbtJqsazA+vwZjXYNZrbpGuXpnX3fa\nhu5+f9e+FzijZ9y6rm2xdknSmIwS+tuBo1fgXAps62l/a3cVzwXAwap6HPgS8Kokz+8+wH1V1yZJ\nGpO+3psmuZX5c/KnJnmM+atwrgJuS/IO4AfAm7vhdwIXAruBnwBvA6iqA0k+CnytG/eRqjr2w2FJ\n0irqK/Sr6uJFul6xwNgC3rvIcm4Abui7OknSivIbuZLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakh\nhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLo\nS1JDDH1JasjQoZ/kJUke7LkdSvL+JB9Osren/cKeea5IsjvJI0levTKbIEnq14nDzlhVjwDnASQ5\nAdgLfAF4G/CJqvpY7/gkZwGbgbOBXwf+MsmLq+qpYWuQJA1mpU7vvAJ4tKp+sMSYi4DZqnqyqr4P\n7AbOX6H1S5L6kKoafSHJDcDXq+raJB8GLgMOAQ8AH6iqJ5JcC9xfVZ/t5rkeuKuqPr/A8rYAWwAm\nJyc3zs7ODlXX/gMH2Xd4qFlHcu7pJy/ZPzc3x8TExJiq6Z91Dcbn12CsazCj1DUzM7OzqqYW6hv6\n9M5RSZ4NvB64omu6DvgoUN391cDbB1lmVW0FtgJMTU3V9PT0ULVdc8s2rt418iYObM8l00v279ix\ng2G3aTVZ12B8fg3GugazWnWtxOmd1zB/lL8PoKr2VdVTVfVT4NP87BTOXuCMnvnWdW2SpDFZidC/\nGLj16IMkp/X0vRF4qJveDmxO8pwkZwIbgK+uwPolSX0a6b1pkpOA3wHe1dP8n5Kcx/zpnT1H+6rq\n4SS3Ad8EjgDv9codSRqvkUK/qn4M/NoxbW9ZYvyVwJWjrFOSNDy/kStJDTH0Jakhhr4kNcTQl6SG\nGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1Jaoih\nL0kNMfQlqSGGviQ1ZOTQT7Inya4kDyZ5oGv71SR3J/lud//8rj1JPplkd5JvJHnpqOuXJPVvpY70\nZ6rqvKqa6h5fDtxTVRuAe7rHAK8BNnS3LcB1K7R+SVIfVuv0zkXATd30TcAbetpvrnn3A6ckOW2V\napAkHSNVNdoCku8DTwAF/Neq2prkR1V1Stcf4ImqOiXJHcBVVfXlru8e4INV9cAxy9zC/DsBJicn\nN87Ozg5V2/4DB9l3eNgtG965p5+8ZP/c3BwTExNjqqZ/1jUYn1+Dsa7BjFLXzMzMzp4zLz/nxJGq\nmvdPq2pvkn8A3J3k272dVVVJBvrLUlVbga0AU1NTNT09PVRh19yyjat3rcQmDmbPJdNL9u/YsYNh\nt2k1WddgfH4NxroGs1p1jXx6p6r2dvf7gS8A5wP7jp626e73d8P3Amf0zL6ua5MkjcFIoZ/kpCTP\nOzoNvAp4CNgOXNoNuxTY1k1vB97aXcVzAXCwqh4fpQZJUv9GfW86CXxh/rQ9JwJ/WlX/PcnXgNuS\nvAP4AfDmbvydwIXAbuAnwNtGXL8kaQAjhX5VfQ/4zQXafwi8YoH2At47yjolScPzG7mS1BBDX5Ia\nYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktSQ8f9EoFbV+sv/Yuh5P3DuES4bcv49V712\n6PVKGh+P9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN8ctZkrSEUb7wOIobN520\nKsv1SF+SGjJ06Cc5I8m9Sb6Z5OEkv9e1fzjJ3iQPdrcLe+a5IsnuJI8kefVKbIAkqX+jnN45Anyg\nqr6e5HnAziR3d32fqKqP9Q5OchawGTgb+HXgL5O8uKqeGqEGSdIAhj7Sr6rHq+rr3fTfAd8CTl9i\nlouA2ap6sqq+D+wGzh92/ZKkwaWqRl9Ish64DzgH+H3gMuAQ8ADz7waeSHItcH9Vfbab53rgrqr6\n/ALL2wJsAZicnNw4Ozs7VF37Dxxk3+GhZh3JuaefvGT/3NwcExMTq7LuXXsPDj3v5HMZen8tt82j\nWM39NYoWn1+j+EWta5TX1CjOPPmEoffXzMzMzqqaWqhv5Kt3kkwAtwPvr6pDSa4DPgpUd3818PZB\nlllVW4GtAFNTUzU9PT1Ubdfcso2rd43/AqU9l0wv2b9jxw6G3ablDPvTyDD/08rD7q/ltnkUq7m/\nRtHi82sUv6h1jfKaGsWNm05alf010tU7SZ7FfODfUlV/BlBV+6rqqar6KfBpfnYKZy9wRs/s67o2\nSdKYjHL1ToDrgW9V1cd72k/rGfZG4KFuejuwOclzkpwJbAC+Ouz6JUmDG+W96W8BbwF2JXmwa/tD\n4OIk5zF/emcP8C6Aqno4yW3AN5m/8ue9XrkjSeM1dOhX1ZeBLNB15xLzXAlcOew6JUmj8Ru5ktQQ\nf3tHUt9G+R2aD5x7ZOgrYfZc9dqh16uf55G+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN\nMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGjD30k2xK\n8kiS3UkuH/f6JallYw39JCcAfwy8BjgLuDjJWeOsQZJaNu4j/fOB3VX1var6v8AscNGYa5CkZqWq\nxrey5E3Apqp6Z/f4LcDLqup9x4zbAmzpHr4EeGTIVZ4K/O2Q864m6xqMdQ3GugbzTKzrH1XVCxbq\nOHH4elZPVW0Fto66nCQPVNXUCpS0oqxrMNY1GOsaTGt1jfv0zl7gjJ7H67o2SdIYjDv0vwZsSHJm\nkmcDm4HtY65Bkpo11tM7VXUkyfuALwEnADdU1cOruMqRTxGtEusajHUNxroG01RdY/0gV5K0tvxG\nriQ1xNCXpIY8I0J/uZ92SPKcJJ/r+r+SZP1xUtdlSf5Pkge72zvHUNMNSfYneWiR/iT5ZFfzN5K8\ndLVr6rOu6SQHe/bVvx9TXWckuTfJN5M8nOT3Fhgz9n3WZ11j32dJfjnJV5P8TVfXf1hgzNhfj33W\nNfbXY8+6T0jyv5LcsUDfyu6vqvqFvjH/gfCjwIuAZwN/A5x1zJj3AJ/qpjcDnztO6roMuHbM++vl\nwEuBhxbpvxC4CwhwAfCV46SuaeCONXh+nQa8tJt+HvCdBf4dx77P+qxr7Pus2wcT3fSzgK8AFxwz\nZi1ej/3UNfbXY8+6fx/404X+vVZ6fz0TjvT7+WmHi4CbuunPA69IkuOgrrGrqvuAA0sMuQi4uebd\nD5yS5LTjoK41UVWPV9XXu+m/A74FnH7MsLHvsz7rGrtuH8x1D5/V3Y69WmTsr8c+61oTSdYBrwU+\ns8iQFd1fz4TQPx343z2PH+PpT/6/H1NVR4CDwK8dB3UB/IvulMDnk5yxQP+49Vv3Wvgn3dvzu5Kc\nPe6Vd2+r/zHzR4m91nSfLVEXrME+605VPAjsB+6uqkX31xhfj/3UBWvzevwvwB8AP12kf0X31zMh\n9H+R/Tmwvqp+A7ibn/0119N9nfnfE/lN4Brgi+NceZIJ4Hbg/VV1aJzrXsoyda3JPquqp6rqPOa/\ncX9+knPGsd7l9FHX2F+PSV4H7K+qnau9rqOeCaHfz087/P2YJCcCJwM/XOu6quqHVfVk9/AzwMZV\nrqkfx+VPZVTVoaNvz6vqTuBZSU4dx7qTPIv5YL2lqv5sgSFrss+Wq2st91m3zh8B9wKbjulai9fj\nsnWt0evxt4DXJ9nD/Cngf5bks8eMWdH99UwI/X5+2mE7cGk3/Sbgr6r7VGQt6zrmvO/rmT8vu9a2\nA2/trki5ADhYVY+vdVFJ/uHR85hJzmf+ubvqQdGt83rgW1X18UWGjX2f9VPXWuyzJC9Icko3/Vzg\nd4BvHzNs7K/Hfupai9djVV1RVeuqaj3zGfFXVfWvjhm2ovvruPyVzUHUIj/tkOQjwANVtZ35F8d/\nS7Kb+Q8LNx8ndf2bJK8HjnR1XbbadSW5lfmrOk5N8hjwIeY/1KKqPgXcyfzVKLuBnwBvW+2a+qzr\nTcC/TnIEOAxsHsMfbpg/EnsLsKs7Hwzwh8ALe2pbi33WT11rsc9OA27K/H+Y9EvAbVV1x1q/Hvus\na+yvx8Ws5v7yZxgkqSHPhNM7kqQ+GfqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIf8fosmZRtRl\nzjQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cFmiO6ThJZbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def to_multi_label(target):\n",
        "#     multi_label = np.zeros((len(target), NUM_CLASSES))\n",
        "#     for i in range(len(target)):\n",
        "#         j = target[i] + 1\n",
        "#         multi_label[i][:j] = 1\n",
        "#     return np.array(multi_label)\n",
        "# multi_y = to_multi_label(y)\n",
        "# for j in range(5):\n",
        "#     print('original: ', y[j])\n",
        "#     print('multi-label: ', multi_y[j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FBpQ4QcNJZbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.legacy import interfaces\n",
        "from keras.optimizers import Optimizer\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class AdamAccumulate_v1(Optimizer):\n",
        "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
        "                 epsilon=None, decay=0., amsgrad=False, accum_iters=20, **kwargs):\n",
        "        super(AdamAccumulate, self).__init__(**kwargs)\n",
        "        with K.name_scope(self.__class__.__name__):\n",
        "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "            self.effective_iterations = K.variable(0, dtype='int64', name='effective_iterations')\n",
        "\n",
        "            self.lr = K.variable(lr, name='lr')\n",
        "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
        "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
        "            self.decay = K.variable(decay, name='decay')\n",
        "        if epsilon is None:\n",
        "            epsilon = K.epsilon()\n",
        "        self.epsilon = epsilon\n",
        "        self.initial_decay = decay\n",
        "        self.amsgrad = amsgrad\n",
        "        self.accum_iters = K.variable(accum_iters, dtype='int64')\n",
        "\n",
        "    @interfaces.legacy_get_updates_support\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "\n",
        "        self.updates = [K.update(self.iterations, self.iterations + 1)]\n",
        "\n",
        "        flag = K.equal(self.iterations % self.accum_iters, self.accum_iters - 1)\n",
        "        flag = K.cast(flag, K.floatx())\n",
        "\n",
        "        self.updates.append(K.update(self.effective_iterations,\n",
        "                                     self.effective_iterations + K.cast(flag, 'int64')))\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr = lr * (1. / (1. + self.decay * K.cast(self.effective_iterations,\n",
        "                                                      K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.effective_iterations, K.floatx()) + 1\n",
        "\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
        "                     (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        gs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "\n",
        "        if self.amsgrad:\n",
        "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        else:\n",
        "            vhats = [K.zeros(1) for _ in params]\n",
        "        self.weights = [self.iterations] + ms + vs + vhats\n",
        "\n",
        "        for p, g, m, v, vhat, gg in zip(params, grads, ms, vs, vhats, gs):\n",
        "\n",
        "            gg_t = (1 - flag) * (gg + g)\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * (gg + flag * g) / K.cast(self.accum_iters, K.floatx())\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(\n",
        "                (gg + flag * g) / K.cast(self.accum_iters, K.floatx()))\n",
        "\n",
        "            if self.amsgrad:\n",
        "                vhat_t = K.maximum(vhat, v_t)\n",
        "                p_t = p - flag * lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n",
        "                self.updates.append(K.update(vhat, vhat_t))\n",
        "            else:\n",
        "                p_t = p - flag * lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n",
        "\n",
        "            self.updates.append((m, flag * m_t + (1 - flag) * m))\n",
        "            self.updates.append((v, flag * v_t + (1 - flag) * v))\n",
        "            self.updates.append((gg, gg_t))\n",
        "            new_p = p_t\n",
        "\n",
        "            # Apply constraints.\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                new_p = p.constraint(new_p)\n",
        "\n",
        "            self.updates.append(K.update(p, new_p))\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'lr': float(K.get_value(self.lr)),\n",
        "                  'beta_1': float(K.get_value(self.beta_1)),\n",
        "                  'beta_2': float(K.get_value(self.beta_2)),\n",
        "                  'decay': float(K.get_value(self.decay)),\n",
        "                  'epsilon': self.epsilon,\n",
        "                  'amsgrad': self.amsgrad}\n",
        "        base_config = super(AdamAccumulate, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class AdamAccumulate(Optimizer):\n",
        "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
        "                 epsilon=None, decay=0., amsgrad=False, accum_iters=2, **kwargs):\n",
        "        if accum_iters < 1:\n",
        "            raise ValueError('accum_iters must be >= 1')\n",
        "        super(AdamAccumulate, self).__init__(**kwargs)\n",
        "        with K.name_scope(self.__class__.__name__):\n",
        "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "            self.lr = K.variable(lr, name='lr')\n",
        "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
        "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
        "            self.decay = K.variable(decay, name='decay')\n",
        "        if epsilon is None:\n",
        "            epsilon = K.epsilon()\n",
        "        self.epsilon = epsilon\n",
        "        self.initial_decay = decay\n",
        "        self.amsgrad = amsgrad\n",
        "        self.accum_iters = K.variable(accum_iters, K.dtype(self.iterations))\n",
        "        self.accum_iters_float = K.cast(self.accum_iters, K.floatx())\n",
        "\n",
        "    @interfaces.legacy_get_updates_support\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "\n",
        "        completed_updates = K.cast(K.tf.floor(self.iterations / self.accum_iters), K.floatx())\n",
        "\n",
        "        if self.initial_decay > 0:\n",
        "            lr = lr * (1. / (1. + self.decay * completed_updates))\n",
        "\n",
        "        t = completed_updates + 1\n",
        "\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        # self.iterations incremented after processing a batch\n",
        "        # batch:              1 2 3 4 5 6 7 8 9\n",
        "        # self.iterations:    0 1 2 3 4 5 6 7 8\n",
        "        # update_switch = 1:        x       x    (if accum_iters=4)\n",
        "        update_switch = K.equal((self.iterations + 1) % self.accum_iters, 0)\n",
        "        update_switch = K.cast(update_switch, K.floatx())\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        gs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "\n",
        "        if self.amsgrad:\n",
        "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        else:\n",
        "            vhats = [K.zeros(1) for _ in params]\n",
        "\n",
        "        self.weights = [self.iterations] + ms + vs + vhats\n",
        "\n",
        "        for p, g, m, v, vhat, tg in zip(params, grads, ms, vs, vhats, gs):\n",
        "\n",
        "            sum_grad = tg + g\n",
        "            avg_grad = sum_grad / self.accum_iters_float\n",
        "\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * avg_grad\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(avg_grad)\n",
        "\n",
        "            if self.amsgrad:\n",
        "                vhat_t = K.maximum(vhat, v_t)\n",
        "                p_t = p - lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n",
        "                self.updates.append(K.update(vhat, (1 - update_switch) * vhat + update_switch * vhat_t))\n",
        "            else:\n",
        "                p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n",
        "\n",
        "            self.updates.append(K.update(m, (1 - update_switch) * m + update_switch * m_t))\n",
        "            self.updates.append(K.update(v, (1 - update_switch) * v + update_switch * v_t))\n",
        "            self.updates.append(K.update(tg, (1 - update_switch) * sum_grad))\n",
        "            new_p = p_t\n",
        "\n",
        "            # Apply constraints.\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                new_p = p.constraint(new_p)\n",
        "\n",
        "            self.updates.append(K.update(p, (1 - update_switch) * p + update_switch * new_p))\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'lr': float(K.get_value(self.lr)),\n",
        "                  'beta_1': float(K.get_value(self.beta_1)),\n",
        "                  'beta_2': float(K.get_value(self.beta_2)),\n",
        "                  'decay': float(K.get_value(self.decay)),\n",
        "                  'epsilon': self.epsilon,\n",
        "                  'amsgrad': self.amsgrad}\n",
        "        base_config = super(AdamAccumulate, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5bPEf5QhJZby",
        "colab_type": "code",
        "outputId": "c3044567-681a-4ca8-e272-e68008ad2173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "y = to_categorical(y, num_classes=NUM_CLASSES)\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n",
        "                                                      stratify=y, random_state=8)\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(valid_x.shape)\n",
        "print(valid_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3112,)\n",
            "(3112, 5)\n",
            "(550,)\n",
            "(550, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mPXTDtJzJZb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/aleju/imgaug\n",
        "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "seq = iaa.Sequential([\n",
        "    sometimes(\n",
        "        iaa.OneOf([\n",
        "            iaa.Add((-10, 10), per_channel=0.5),\n",
        "            iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "            iaa.ContrastNormalization((0.9, 1.1), per_channel=0.5)\n",
        "        ])\n",
        "    ),\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Crop(percent=(0, 0.1)),\n",
        "    iaa.Flipud(0.5)\n",
        "],random_order=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ezaf9_f-JZb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class My_Generator(Sequence):\n",
        "\n",
        "    def __init__(self, image_filenames, labels,\n",
        "                 batch_size, is_train=False,\n",
        "                 mix=False, augment=False):\n",
        "        self.image_filenames, self.labels = image_filenames, labels\n",
        "        self.batch_size = batch_size\n",
        "        self.is_train = is_train\n",
        "        self.is_augment = augment\n",
        "        if(self.is_train):\n",
        "            self.on_epoch_end()\n",
        "        self.is_mix = mix\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        if(self.is_train):\n",
        "            return self.train_generate(batch_x, batch_y)\n",
        "        return self.valid_generate(batch_x, batch_y)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if(self.is_train):\n",
        "            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n",
        "    \n",
        "    def mix_up(self, x, y):\n",
        "        lam = np.random.beta(0.2, 0.4)\n",
        "        ori_index = np.arange(int(len(x)))\n",
        "        index_array = np.arange(int(len(x)))\n",
        "        np.random.shuffle(index_array)        \n",
        "        \n",
        "        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n",
        "        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n",
        "        \n",
        "        return mixed_x, mixed_y\n",
        "\n",
        "    def train_generate(self, batch_x, batch_y):\n",
        "        batch_images = []\n",
        "        for (sample, label) in zip(batch_x, batch_y):\n",
        "            img = cv2.imread(root + '/train_images/'+sample+'.png')\n",
        "            img = cv2.resize(img, (SIZE, SIZE))\n",
        "            if(self.is_augment):\n",
        "                img = seq.augment_image(img)\n",
        "            batch_images.append(img)\n",
        "        batch_images = np.array(batch_images, np.float32) / 255\n",
        "        batch_y = np.array(batch_y, np.float32)\n",
        "        if(self.is_mix):\n",
        "            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n",
        "        return batch_images, batch_y\n",
        "\n",
        "    def valid_generate(self, batch_x, batch_y):\n",
        "        batch_images = []\n",
        "        for (sample, label) in zip(batch_x, batch_y):\n",
        "            img = cv2.imread(root + '/train_images/'+sample+'.png')\n",
        "            img = cv2.resize(img, (SIZE, SIZE))\n",
        "            batch_images.append(img)\n",
        "        batch_images = np.array(batch_images, np.float32) / 255\n",
        "        batch_y = np.array(batch_y, np.float32)\n",
        "        return batch_images, batch_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "c9O4QpYiJZb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
        "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import metrics\n",
        "from keras.optimizers import Adam \n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.models import Model, Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MkS-xVtGJZcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "function = \"softmax\"\n",
        "def create_model(input_shape, n_out):\n",
        "    \n",
        "    input_tensor = Input(shape=input_shape)\n",
        "    base_model = ResNet50(include_top=False,\n",
        "                   weights=None,#'imagenet',#None,\n",
        "                   input_tensor=input_tensor)\n",
        "    #base_model.load_weights('../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    final_output = Dense(n_out, activation=function, name='final_output')(x)\n",
        "    model = Model(input_tensor, final_output)\n",
        "    \n",
        "    '''\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                            input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    #model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    #model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dense(n_out, activation='softmax'))\n",
        "    '''\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z1xSwBGZJZcG",
        "colab_type": "code",
        "outputId": "194633c8-9cfe-46ca-880b-ff98c4622854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "# create callbacks list\n",
        "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
        "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
        "\n",
        "epochs = 30; batch_size = 32\n",
        "checkpoint = ModelCheckpoint('../Resnet50_baseline_custom.h5', monitor='val_loss', verbose=1, \n",
        "                             save_best_only=True, mode='min', save_weights_only = True)\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
        "                                   verbose=1, mode='min', epsilon=0.0001)\n",
        "early = EarlyStopping(monitor=\"val_loss\", \n",
        "                      mode=\"min\", \n",
        "                      patience=9)\n",
        "\n",
        "csv_logger = CSVLogger(filename='../working/training_log.csv',\n",
        "                       separator=',',\n",
        "                       append=True)\n",
        "# callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early]\n",
        "\n",
        "train_generator = My_Generator(train_x, train_y, 128, is_train=True)\n",
        "train_mixup = My_Generator(train_x, train_y, batch_size, is_train=True, mix=False, augment=True)\n",
        "valid_generator = My_Generator(valid_x, valid_y, batch_size, is_train=False)\n",
        "\n",
        "model = create_model(\n",
        "    input_shape=(SIZE,SIZE,3), \n",
        "    n_out=NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NCC5LWBDJZcK",
        "colab_type": "code",
        "outputId": "693f1d68-c657-48bc-9e55-28424d1b6c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 306, 306, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 150, 150, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 150, 150, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 150, 150, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 152, 152, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 75, 75, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 75, 75, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 75, 75, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 75, 75, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 75, 75, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 75, 75, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 75, 75, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 75, 75, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 75, 75, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 75, 75, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 75, 75, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 75, 75, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 75, 75, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 75, 75, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 75, 75, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 75, 75, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 75, 75, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 75, 75, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 75, 75, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 75, 75, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 75, 75, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 75, 75, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 75, 75, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 75, 75, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 75, 75, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 75, 75, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 75, 75, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 75, 75, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 75, 75, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 75, 75, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 75, 75, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 75, 75, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 75, 75, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 38, 38, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 38, 38, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 38, 38, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 38, 38, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 38, 38, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 38, 38, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 38, 38, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 38, 38, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 38, 38, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 38, 38, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 38, 38, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 38, 38, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 38, 38, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 38, 38, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 38, 38, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 38, 38, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 38, 38, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 38, 38, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 38, 38, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 38, 38, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 38, 38, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 38, 38, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 38, 38, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 38, 38, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 38, 38, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 38, 38, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 38, 38, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 38, 38, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 38, 38, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 38, 38, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 38, 38, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 38, 38, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 38, 38, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 38, 38, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 38, 38, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 38, 38, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 38, 38, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 38, 38, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 38, 38, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 38, 38, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 38, 38, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 38, 38, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 19, 19, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 19, 19, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 19, 19, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 19, 19, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 19, 19, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 19, 19, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 19, 19, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 19, 19, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 19, 19, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 19, 19, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 19, 19, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 19, 19, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 19, 19, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 19, 19, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 19, 19, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 19, 19, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 19, 19, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 19, 19, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 19, 19, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 19, 19, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 19, 19, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 19, 19, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 19, 19, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 19, 19, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 19, 19, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 19, 19, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 19, 19, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 19, 19, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 19, 19, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 19, 19, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 19, 19, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 19, 19, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 19, 19, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 19, 19, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 19, 19, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 19, 19, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 10, 10, 512)  524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 10, 10, 512)  2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 10, 10, 512)  0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 10, 10, 512)  2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 10, 10, 512)  2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 10, 10, 512)  0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 10, 10, 2048) 1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 10, 10, 2048) 2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 10, 10, 2048) 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 10, 10, 2048) 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 10, 10, 2048) 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 10, 10, 2048) 0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 10, 10, 512)  1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 10, 10, 512)  2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 10, 10, 512)  0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 10, 10, 512)  2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 10, 10, 512)  2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 10, 10, 512)  0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 10, 10, 2048) 1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 10, 10, 2048) 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 10, 10, 2048) 0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 10, 10, 2048) 0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 10, 10, 512)  1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 10, 10, 512)  2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 10, 10, 512)  0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 10, 10, 512)  2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 10, 10, 512)  2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 10, 10, 512)  0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 10, 10, 2048) 1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 10, 10, 2048) 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 10, 10, 2048) 0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 10, 10, 2048) 0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         2098176     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "final_output (Dense)            (None, 5)            5125        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 25,691,013\n",
            "Trainable params: 25,637,893\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UrATbtU6JZcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "class QWKEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), batch_size=64, interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.batch_size = batch_size\n",
        "        self.valid_generator, self.y_val = validation_data\n",
        "        self.history = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict_generator(generator=self.valid_generator,\n",
        "                                                  steps=np.ceil(float(len(self.y_val)) / float(self.batch_size)),\n",
        "                                                  workers=1, use_multiprocessing=True,\n",
        "                                                  verbose=1)\n",
        "            def flatten(y):\n",
        "                return np.argmax(y, axis=1).reshape(-1)\n",
        "                # return np.sum(y.astype(int), axis=1) - 1\n",
        "            \n",
        "            score = cohen_kappa_score(flatten(self.y_val),\n",
        "                                      flatten(y_pred),\n",
        "                                      labels=[0,1,2,3,4],\n",
        "                                      weights='quadratic')\n",
        "#             print(flatten(self.y_val)[:5])\n",
        "#             print(flatten(y_pred)[:5])\n",
        "            print(\"\\n epoch: %d - QWK_score: %.6f \\n\" % (epoch+1, score))\n",
        "            self.history.append(score)\n",
        "            if score >= max(self.history):\n",
        "                print('save checkpoint: ', score)\n",
        "                self.model.save('../Resnet50_bestqwk.h5')\n",
        "\n",
        "qwk = QWKEvaluation(validation_data=(valid_generator, valid_y),\n",
        "                    batch_size=batch_size, interval=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y1XSQHiFJZcS",
        "colab_type": "code",
        "outputId": "790ed8ef-0fe4-470e-a8fe-522103dd1e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "\n",
        "# warm up model\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for i in range(-5,0):\n",
        "    model.layers[i].trainable = True\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    # loss='binary_crossentropy',\n",
        "    optimizer=Adam(1e-3))\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=np.ceil(float(len(train_y)) / float(128)),\n",
        "    epochs=2,\n",
        "    workers=WORKERS, use_multiprocessing=True,\n",
        "    verbose=1,\n",
        "    callbacks=[qwk])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "25/25 [==============================] - 565s 23s/step - loss: 4.7306\n",
            "18/18 [==============================] - 373s 21s/step\n",
            "\n",
            " epoch: 1 - QWK_score: 0.000000 \n",
            "\n",
            "save checkpoint:  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1b0005bb0345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWORKERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     callbacks=[qwk])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    253\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-1d0cefb36d6e>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'save checkpoint: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../working/Resnet50_bestqwk.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m qwk = QWKEvaluation(validation_data=(valid_generator, valid_y),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_write_to_gcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_wrapper\u001b[0;34m(obj, filepath, overwrite, *args, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msave_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproceed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m             \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '../working/Resnet50_bestqwk.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xoQWh9BCJZcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train all layers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early, qwk]\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            # loss=kappa_loss,\n",
        "            # loss='binary_crossentropy',\n",
        "            optimizer=Adam(lr=1e-4),\n",
        "            #optimizer=AdamAccumulate(lr=1e-4, accum_iters=2),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_mixup,\n",
        "    steps_per_epoch=np.ceil(float(len(train_x)) / float(batch_size)),\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=np.ceil(float(len(valid_x)) / float(batch_size)),\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    workers=1, use_multiprocessing=False,\n",
        "    callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SFbDQQV5JZcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit = pd.read_csv(root + '/sample_submission.csv')\n",
        "# model.load_weights('../working/Resnet50.h5')\n",
        "model.load_weights('../Resnet50_bestqwk.h5')\n",
        "predicted = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SQo17aLUJZcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, name in tqdm(enumerate(submit['id_code'])):\n",
        "    path = os.path.join(root + '/test_images/', name+'.png')\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.resize(image, (SIZE, SIZE))\n",
        "    score_predict = model.predict((image[np.newaxis])/255)\n",
        "    label_predict = np.argmax(score_predict)\n",
        "    # label_predict = score_predict.astype(int).sum() - 1\n",
        "    predicted.append(str(label_predict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eNx_GCErJZcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit['diagnosis'] = predicted\n",
        "submit.to_csv('submission.csv', index=False)\n",
        "submit.head()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
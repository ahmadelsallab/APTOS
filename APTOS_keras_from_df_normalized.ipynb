{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.autonotebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nroot = '/kaggle/input/aptos2019-blindness-detection/'\ntrain_img_path = os.path.join(root,'train_images')\ntrain_path = os.path.join(root,'train.csv')\ntest_img_path = os.path.join(root,'test_images')\ntest_path = os.path.join(root,'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ntrain_data = pd.read_csv(train_path)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_classes = train_data.diagnosis.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = train_data.diagnosis.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.diagnosis.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['id_code'] = train_data['id_code'].apply(lambda x:x+'.png')\ntrain_data['diagnosis'] = train_data['diagnosis'].apply(lambda x:str(x))\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the size of our input data\nsz=224","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',\n                        input_shape=(sz, sz, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(n_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\n\n\n'''\nopt = Adam(lr=1e-4)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n'''\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(train_data, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import keras\n#from keras.models import Sequential, Model \nfrom keras.preprocessing.image import ImageDataGenerator\n#from keras.applications.vgg16 import VGG16, preprocess_input\n#from keras.layers import Dropout, Flatten,Dense\n\n\nimport numpy as np\nimport os\nfrom matplotlib import image,patches,patheffects\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# our batch size\nbs=32\n\n# No need for preprocess_fn as it will be handled in target_sz of the generator\n\nimport cv2\ndef preprocess_input(img):\n    #return img/255#cv2.resize(img, (sz,sz))\n    return img.astype('float32')/255\n\n# preprocess_input is for VGG16 in our case\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n                                   rotation_range=20,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   shear_range=0.1,\n                                   zoom_range=0.1,\n                                   horizontal_flip=True) \n\nvalid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) \n\n\ntrain_batches = train_datagen.flow_from_dataframe(train_df, # The df\n                                                  train_img_path, # Place on desk\n                                                  x_col='id_code', # The column to get x\n                                                  y_col='diagnosis', # The column to get y\n                                                  #has_ext=True, \n                                                  target_size=(sz, sz), \n                                                  color_mode='rgb', \n                                                  classes=None, \n                                                  class_mode='categorical', \n                                                  batch_size=bs, \n                                                  shuffle=True)\n\n\n\nvalid_batches = valid_datagen.flow_from_dataframe(val_df, \n                                                  train_img_path, \n                                                  x_col='id_code', \n                                                  y_col='diagnosis', \n                                                  #has_ext=True, \n                                                  target_size=(sz, sz), \n                                                  color_mode='rgb', \n                                                  classes=None,#list(train_batches.class_indices),#classes, \n                                                  class_mode='categorical', \n                                                  batch_size=bs, \n                                                  shuffle=False)\n\nNbClasses = len(train_batches.class_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\nfrom keras.callbacks import Callback\nclass Kappa(Callback):\n    \n    def on_train_begin(self, logs={}):\n        self._data = []\n\n    def on_epoch_end(self, batch, logs={}):\n        X_val, y_val = self.validation_data[0], self.validation_data[1]\n        y_predict = np.asarray(model.predict(X_val))\n\n        y_val = np.argmax(y_val, axis=1)\n        y_predict = np.argmax(y_predict, axis=1)\n\n        self._data.append({\n            'val_kappa': cohen_kappa_score(y_val, y_predict),\n        })\n        return\n\n    def get_data(self):\n        return self._data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    quadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return 1.0 - numerator / denominator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val = []\ny_val = []\ns = 0\nvalidation_steps = valid_batches.n // valid_batches.batch_size\nprint(validation_steps)\nfor b in tqdm(valid_batches):\n#for s in validation_steps:\n    #b = next(valid_batches)\n    #print(s)\n    if s > validation_steps: # to prevent looping forever\n        break\n    s+=1\n    X_val.append(b[0])\n    y_val.append(b[1])\nX_val = np.concatenate(X_val)    \ny_val = np.concatenate(y_val) \n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_val.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\n\nclass QWKP(Callback):\n    \n    def on_train_begin(self, logs={}):\n        self._data = []\n\n    def on_epoch_end(self, batch, logs={}):\n        #X_val, y_val = self.validation_data[0], self.validation_data[1]\n\n        \n        y_predict = np.asarray(model.predict(X_val))\n\n        y_val_ = np.argmax(y_val, axis=1)\n        y_predict = np.argmax(y_predict, axis=1)\n        qwkp =  cohen_kappa_score(y_val_, y_predict)#quadratic_weighted_kappa(y_val_, y_predict)\n        print('Validation qwkp: ', str(qwkp))\n        self._data.append({\n            'val_kappa':qwkp,\n        })\n        return\n\n    def get_data(self):\n        return self._data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 2\n\nhistory = model.fit_generator(train_batches,\n                              steps_per_epoch = train_batches.n // train_batches.batch_size,\n                              epochs=epochs,\n                              validation_data=valid_batches,\n                              validation_steps = valid_batches.n // valid_batches.batch_size,\n                              callbacks=[QWKP()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get a sample image\nb = next(valid_batches)\nimg = b[0][5]\nprint(img.shape)\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.max(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(b[1][5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.expand_dims(img, 0)\npreds = model.predict(x)\nidx = np.argmax(preds[0])\nidx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(model, to_file='model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_conv_layer.output_shape[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n# This is the index entry in the prediction vector\noutput = model.output[:, idx]\n\n# The is the output feature map of the `block5_conv3` layer,\n# the last convolutional layer in VGG16\nlast_conv_layer =model.layers[6] #model.get_layer('block5_conv3')\n\n# This is the gradient of the \"african elephant\" class with regard to\n# the output feature map of `block5_conv3`\ngrads = K.gradients(output, last_conv_layer.output)[0]\n\n# This is a vector of shape (512,), where each entry\n# is the mean intensity of the gradient over a specific feature map channel\npooled_grads = K.mean(grads, axis=(0, 1, 2))\n\n# This function allows us to access the values of the quantities we just defined:\n# `pooled_grads` and the output feature map of `block5_conv3`,\n# given a sample image\niterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n\n# These are the values of these two quantities, as Numpy arrays,\n# given our sample image of two elephants\npooled_grads_value, conv_layer_output_value = iterate([x])\n\n# We multiply each channel in the feature map array\n# by \"how important this channel is\" with regard to the elephant class\n#for i in range(128):\nfor i in range(last_conv_layer.output_shape[-1]):\n    \n    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n\n# The channel-wise mean of the resulting feature map\n# is our heatmap of class activation\nheatmap = np.mean(conv_layer_output_value, axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heatmap.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heatmap = np.maximum(heatmap, 0)\nheatmap /= np.max(heatmap)\nplt.matshow(heatmap)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\n\n# We resize the heatmap to have the same size as the original image\nheatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n\n# We convert the heatmap to RGB\nheatmap = np.uint8(255 * heatmap)\n#eatmap = np.uint8(heatmap)\n\n# We apply the heatmap to the original image\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n# 0.4 here is a heatmap intensity factor\nsuperimposed_img = heatmap * 0.1 + img\n\n# Save the image to disk\n#cv2.imwrite('elephant_cam.jpg', superimposed_img)\nplt.imshow(superimposed_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nimport cv2\ndef grad_CAM(model, layer, img):\n    x = np.expand_dims(img, 0)\n    preds = model.predict(x)\n    idx = np.argmax(preds[0])\n\n    \n    # This is the index entry in the prediction vector\n    output = model.output[:, idx]\n\n    # The is the output feature map of the `block5_conv3` layer,\n    # the last convolutional layer in VGG16\n    last_conv_layer =model.layers[layer] #model.get_layer('block5_conv3')\n\n    # This is the gradient of the \"african elephant\" class with regard to\n    # the output feature map of `block5_conv3`\n    grads = K.gradients(output, last_conv_layer.output)[0]\n\n    # This is a vector of shape (512,), where each entry\n    # is the mean intensity of the gradient over a specific feature map channel\n    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n\n    # This function allows us to access the values of the quantities we just defined:\n    # `pooled_grads` and the output feature map of `block5_conv3`,\n    # given a sample image\n    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n\n    # These are the values of these two quantities, as Numpy arrays,\n    # given our sample image of two elephants\n    pooled_grads_value, conv_layer_output_value = iterate([x])\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the elephant class\n    for i in range(last_conv_layer.output_shape[-1]):\n        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n\n    # The channel-wise mean of the resulting feature map\n    # is our heatmap of class activation\n    heatmap = np.mean(conv_layer_output_value, axis=-1)\n    \n    heatmap = np.maximum(heatmap, 0)\n    heatmap /= np.max(heatmap)\n    #plt.matshow(heatmap)\n    #plt.show()    \n    heatmap_raw = heatmap\n    \n    # We resize the heatmap to have the same size as the original image\n    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n\n    # We convert the heatmap to RGB\n    heatmap = np.uint8(255 * heatmap)\n    #eatmap = np.uint8(heatmap)\n\n    # We apply the heatmap to the original image\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n    # 0.4 here is a heatmap intensity factor\n    superimposed_img = heatmap * 0.1 + img\n\n    # Save the image to disk\n    #cv2.imwrite('elephant_cam.jpg', superimposed_img)\n    #plt.imshow(superimposed_img)\n    return superimposed_img, heatmap_raw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get a sample image\nb = next(valid_batches)\nimg_idx = 5\nimg = b[0][img_idx]\nprint(img.shape)\nplt.imshow(img)\nplt.show()\nx = np.expand_dims(img, 0)\npreds = model.predict(x)\nidx = np.argmax(preds[0])\nprint('Pred class: ', str(idx), ' Correct class: ', str(np.argmax(b[1][img_idx])))\nsuperimposed_img, heatmap = grad_CAM(model=model, layer=6, img=img)\nplt.imshow(heatmap)\nplt.show()\nplt.imshow(superimposed_img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get a sample image\nb = next(valid_batches)\nfor i in range(5):\n    img_idx = i\n    img = b[0][img_idx]\n    #print(img.shape)\n    plt.imshow(img)\n    plt.show()\n    x = np.expand_dims(img, 0)\n    preds = model.predict(x)\n    idx = np.argmax(preds[0])\n    print('Pred class: ', str(idx), ' Correct class: ', str(np.argmax(b[1][img_idx])))\n    superimposed_img, heatmap = grad_CAM(model=model, layer=6, img=img)\n    plt.imshow(heatmap)\n    plt.show()\n    plt.imshow(superimposed_img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# From the rare class (severe)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[train_data.diagnosis==3].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\nimg = image.load_img(train_img_path + '/' + train_data[train_data.diagnosis==3].iloc[10].id_code + '.png', target_size=(sz,sz))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = preprocess_input(np.array(img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.imshow(img.img_to_array())\n#img = np.array(img)\n#img = image.img_to_array(img)\nprint(img.shape)\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.imshow(img)\nplt.show()\n# = preprocess_input(image.img_to_array(img))\nx = np.expand_dims(img, axis=0)\n\npreds = model.predict(x)\nidx = np.argmax(preds[0])\nprint('Pred class: ', str(idx), ' Correct class: ', str(3))\nsuperimposed_img, heatmap = grad_CAM(model=model, layer=6, img=image.img_to_array(img))\nplt.imshow(heatmap)\nplt.show()\nplt.imshow(superimposed_img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\nfor cl in range(4):\n    print(\"Class: \", str(cl))\n    for i in range(3):\n        \n        img = image.load_img(train_img_path + '/' + train_data[train_data.diagnosis==cl].iloc[i].id_code + '.png', target_size=(sz,sz))\n        img = preprocess_input(np.array(img))\n        \n        plt.imshow(img)\n        plt.show()\n        # = preprocess_input(image.img_to_array(img))\n        x = np.expand_dims(img, axis=0)\n\n        preds = model.predict(x)\n        idx = np.argmax(preds[0])\n        print('Pred class: ', str(idx), ' Correct class: ', str(3))\n        superimposed_img, heatmap = grad_CAM(model=model, layer=6, img=image.img_to_array(img))\n        plt.imshow(heatmap)\n        plt.show()\n        plt.imshow(superimposed_img)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model is not able to recognize the rare class 3 (severe)\nHowever, it seems to capture interesting abnormal areas in the feature map\n\nVisually, the image looks \"abnormal\" in many areas.\n\nIt's usually confused the the \"Moderate\" class."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_predict = np.asarray(model.predict(X_val))\ny_predict = np.argmax(y_predict, axis=1)\n\ny_val_ = np.argmax(y_val, axis=1)\n\ncm = confusion_matrix(y_val_, y_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(cm, annot=True, fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, the best performing classes are the dominant ones."},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(os.path.join(root, 'sample_submission.csv'))\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['id_code'] = submission['id_code'].apply(lambda x:x+'.png')\n#submission['diagnosis'] = submission['diagnosis'].apply(lambda x:str(x))\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['id_code'] = test_df['id_code'].apply(lambda x:x+'.png')\n#test_df['diagnosis'] = test_df['diagnosis'].apply(lambda x:str(x))\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls {test_img_path}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n'''\nsubmission.diagnosis = submission.diagnosis.apply(str)\ntest_batches = test_datagen.flow_from_dataframe(submission, \n                                                  test_img_path, \n                                                  x_col='id_code', \n                                                  y_col='diagnosis', \n                                                  #has_ext=True, \n                                                  target_size=(sz, sz), \n                                                  color_mode='rgb', \n                                                  classes=list(train_batches.class_indices),#classes, \n                                                  class_mode='categorical', #'input',\n                                                  batch_size=bs, \n                                                  shuffle=False)\n'''\n\ntest_batches = test_datagen.flow_from_dataframe(submission,#test_df, \n                                                  test_img_path, \n                                                  x_col='id_code', \n                                                  #y_col='diagnosis', \n                                                  #has_ext=True, \n                                                  target_size=(sz, sz), \n                                                  color_mode='rgb', \n                                                  #classes=list(train_batches.class_indices),#classes, \n                                                  class_mode=None,#'categorical', #'input',\n                                                  batch_size=1, \n                                                  shuffle=False)\n\npreds = []\n'''\ni = 0\nfor batch in test_batches:\n\n    #print(model.predict(batch))\n    preds.append(model.predict(batch))#(np.argmax(model.predict(batch)))\n    i+=1\n    print(i)\n    if i == len(test_df):\n        break\n'''        \n\nfor i in tqdm(range(len(test_df))):\n    batch = next(test_batches)\n    preds.append(np.argmax(model.predict(batch)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nsubmission['diagnosis'] = preds\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}